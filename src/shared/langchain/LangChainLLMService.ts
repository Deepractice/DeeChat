import { BaseChatModel } from "@langchain/core/language_models/chat_models";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import {
  BaseMessage,
  HumanMessage,
  SystemMessage
} from "@langchain/core/messages";

import { LangChainModelFactory } from './LangChainModelFactory';
import { ModelConfigEntity } from '../entities/ModelConfigEntity';
import { enhancedSystemPromptProvider } from '../prompts/EnhancedSystemPromptProvider';
import { llmPromptIntegration } from '../prompts/LLMServiceIntegration';
import { ISystemPromptProvider } from '../interfaces/ISystemPromptProvider';
import { IModelConfigService } from '../interfaces/IModelProvider';
import { DeeChatFeature } from '../prompts/FeatureContextProvider';
import { ConversationContext } from '../prompts/ConversationContextAnalyzer';
import log from 'electron-log';

// MCPå·¥å…·ç›¸å…³ç±»å‹å®šä¹‰
interface MCPTool {
  name: string;
  description?: string;
  inputSchema?: any;
  serverId: string;
  serverName?: string;
}

interface MCPToolCallRequest {
  serverId: string;
  toolName: string;
  arguments: any;
}

interface MCPToolCallResponse {
  success: boolean;
  result?: any;
  error?: string;
}

// MCPæœåŠ¡æ¥å£ï¼ˆæ³¨å…¥ä¾èµ–ï¼‰
interface MCPIntegrationServiceInterface {
  getAllTools(): Promise<MCPTool[]>;
  callTool(request: MCPToolCallRequest): Promise<MCPToolCallResponse>;
}

/**
 * LangChain LLMæœåŠ¡
 * æä¾›ç»Ÿä¸€çš„LLMè°ƒç”¨æ¥å£ï¼Œå†…éƒ¨ä½¿ç”¨LangChainæ¨¡å‹
 */
export class LangChainLLMService {
  private modelCache: Map<string, BaseChatModel> = new Map();
  private configCache: Map<string, ModelConfigEntity> = new Map();
  private promptProvider: ISystemPromptProvider;
  private configService?: IModelConfigService;
  private mcpService?: MCPIntegrationServiceInterface;
  
  // DeeChatæ™ºèƒ½å¯¹è¯ç›¸å…³
  private currentSessionId?: string;
  private isIntentSystemEnabled: boolean = true;

  constructor(
    promptProvider?: ISystemPromptProvider, 
    configService?: IModelConfigService,
    mcpService?: MCPIntegrationServiceInterface
  ) {
    // ä½¿ç”¨å¢å¼ºçš„æç¤ºè¯æä¾›å™¨ä½œä¸ºé»˜è®¤å€¼ï¼Œå‘åå…¼å®¹
    this.promptProvider = promptProvider || enhancedSystemPromptProvider;
    this.configService = configService;
    this.mcpService = mcpService;
    
    // åˆå§‹åŒ–DeeChatæç¤ºè¯ç³»ç»Ÿï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡æ„é€ ï¼‰
    this.initializeDeeChatPrompts();
    
    log.info('ğŸš€ [LangChainæœåŠ¡] åˆå§‹åŒ–DeeChatæ™ºèƒ½å¯¹è¯LLMæœåŠ¡');
  }

  /**
   * åˆå§‹åŒ–DeeChatæç¤ºè¯ç³»ç»Ÿ
   */
  private async initializeDeeChatPrompts(): Promise<void> {
    try {
      if (this.promptProvider === enhancedSystemPromptProvider) {
        await llmPromptIntegration.initializeLLMServicePrompts();
        log.info('âœ… [LangChain] DeeChatæç¤ºè¯ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ');
      }
    } catch (error) {
      log.warn('âš ï¸ [LangChain] DeeChatæç¤ºè¯ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œå°†ä½¿ç”¨åŸºç¡€æç¤ºè¯:', error);
    }
  }

  /**
   * å‘é€æ¶ˆæ¯
   * @param message ç”¨æˆ·æ¶ˆæ¯
   * @param configId æ¨¡å‹é…ç½®ID
   * @param systemPrompt å¯é€‰çš„ç³»ç»Ÿæç¤ºè¯
   * @returns æ¨¡å‹å“åº”
   */
  async sendMessage(
    message: string,
    configId: string,
    systemPrompt?: string
  ): Promise<string> {
    // ç¡®ä¿DeeChatæç¤ºè¯ç³»ç»Ÿå·²åˆå§‹åŒ–
    if (this.promptProvider === enhancedSystemPromptProvider) {
      await llmPromptIntegration.initializeLLMServicePrompts();
    }

    const model = await this.getModel(configId);

    // æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼ˆç°åœ¨ä¼šåŒ…å«DeeChatä¸“å±å†…å®¹ï¼‰
    let finalSystemPrompt = this.promptProvider.buildSystemPrompt();
    
    // å¦‚æœæä¾›äº†é¢å¤–çš„ç³»ç»Ÿæç¤ºè¯ï¼Œè¿½åŠ åˆ°æœ€å
    if (systemPrompt) {
      finalSystemPrompt = finalSystemPrompt ? 
        `${finalSystemPrompt}\n\n${systemPrompt}` : 
        systemPrompt;
    }

    const messages: BaseMessage[] = [
      ...(finalSystemPrompt ? [new SystemMessage(finalSystemPrompt)] : []),
      new HumanMessage(message)
    ];

    const response = await model.invoke(messages);
    return response.content as string;
  }


  /**
   * ä½¿ç”¨ä¸´æ—¶é…ç½®å‘é€æ¶ˆæ¯ï¼ˆä¸ç¼“å­˜æ¨¡å‹ï¼‰
   * @param message ç”¨æˆ·æ¶ˆæ¯
   * @param config ä¸´æ—¶æ¨¡å‹é…ç½®
   * @param systemPrompt å¯é€‰çš„ç³»ç»Ÿæç¤ºè¯
   * @returns æ¨¡å‹å“åº”
   */
  async sendMessageWithConfig(
    message: string,
    config: ModelConfigEntity,
    systemPrompt?: string
  ): Promise<string> {
    // ç›´æ¥åˆ›å»ºæ¨¡å‹ï¼Œä¸ä½¿ç”¨ç¼“å­˜
    log.info(`ğŸ­ [LangChainå·¥å‚] åˆ›å»ºæ¨¡å‹ - Provider: ${config.provider}, Model: ${config.model}`)
    const model = LangChainModelFactory.createChatModel(config);

    // æ„å»ºç³»ç»Ÿæç¤ºè¯
    let finalSystemPrompt = this.promptProvider.buildSystemPrompt();
    
    // å¦‚æœæä¾›äº†é¢å¤–çš„ç³»ç»Ÿæç¤ºè¯ï¼Œè¿½åŠ åˆ°æœ€å
    if (systemPrompt) {
      finalSystemPrompt = finalSystemPrompt ? 
        `${finalSystemPrompt}\n\n${systemPrompt}` : 
        systemPrompt;
    }

    const messages: BaseMessage[] = [
      ...(finalSystemPrompt ? [new SystemMessage(finalSystemPrompt)] : []),
      new HumanMessage(message)
    ];

    const response = await model.invoke(messages);
    return response.content as string;
  }


  /**
   * è·å–æä¾›å•†çš„å¯ç”¨æ¨¡å‹åˆ—è¡¨
   * @param config æ¨¡å‹é…ç½®ï¼ˆç”¨äºè·å–APIå¯†é’¥ç­‰ä¿¡æ¯ï¼‰
   * @returns å¯ç”¨æ¨¡å‹åˆ—è¡¨
   */
  async getAvailableModels(config: ModelConfigEntity): Promise<string[]> {
    const provider = config.provider.toLowerCase();

    switch (provider) {
      case 'gemini':
      case 'google':
        return await this.getGeminiModels(config);

      case 'openai':
        return await this.getOpenAIModels(config);

      case 'claude':
      case 'anthropic':
        // Claudeé€šå¸¸ä¸æä¾›æ¨¡å‹åˆ—è¡¨APIï¼Œè¿”å›é¢„å®šä¹‰åˆ—è¡¨
        return [
          'claude-3-5-sonnet-20241022',
          'claude-3-5-haiku-20241022',
          'claude-3-opus-20240229',
          'claude-3-sonnet-20240229',
          'claude-3-haiku-20240307'
        ];

      case 'custom':
        // è‡ªå®šä¹‰æä¾›å•†ï¼Œå°è¯•é€šè¿‡APIè·å–æ¨¡å‹åˆ—è¡¨
        return await this.getCustomProviderModels(config);

      default:
        throw new Error(`ä¸æ”¯æŒçš„æä¾›å•†: ${provider}`);
    }
  }

  /**
   * ä½¿ç”¨æç¤ºè¯æ¨¡æ¿å‘é€æ¶ˆæ¯
   * @param template æç¤ºè¯æ¨¡æ¿
   * @param variables æ¨¡æ¿å˜é‡
   * @param configId æ¨¡å‹é…ç½®ID
   * @returns æ¨¡å‹å“åº”
   */
  async sendMessageWithTemplate(
    template: ChatPromptTemplate,
    variables: Record<string, any>,
    configId: string
  ): Promise<string> {
    const model = await this.getModel(configId);
    const chain = template.pipe(model);
    const response = await chain.invoke(variables);
    return response.content as string;
  }

  /**
   * å‘é€å¤šè½®å¯¹è¯æ¶ˆæ¯
   * @param messages æ¶ˆæ¯å†å²
   * @param configId æ¨¡å‹é…ç½®ID
   * @returns æ¨¡å‹å“åº”
   */
  async sendConversation(
    messages: BaseMessage[],
    configId: string
  ): Promise<string> {
    const model = await this.getModel(configId);
    const response = await model.invoke(messages);
    return response.content as string;
  }

  /**
   * æµå¼å‘é€æ¶ˆæ¯
   * @param message ç”¨æˆ·æ¶ˆæ¯
   * @param configId æ¨¡å‹é…ç½®ID
   * @param systemPrompt å¯é€‰çš„ç³»ç»Ÿæç¤ºè¯
   * @param onChunk å¤„ç†æ¯ä¸ªchunkçš„å›è°ƒå‡½æ•°
   */
  async streamMessage(
    message: string,
    configId: string,
    systemPrompt?: string,
    onChunk?: (chunk: string) => void
  ): Promise<string> {
    const model = await this.getModel(configId);
    
    const messages: BaseMessage[] = [
      ...(systemPrompt ? [new SystemMessage(systemPrompt)] : []),
      new HumanMessage(message)
    ];
    
    let fullResponse = '';
    const stream = await model.stream(messages);
    
    for await (const chunk of stream) {
      const content = chunk.content as string;
      fullResponse += content;
      if (onChunk) {
        onChunk(content);
      }
    }
    
    return fullResponse;
  }

  /**
   * æ‰¹é‡å¤„ç†æ¶ˆæ¯
   * @param requests æ‰¹é‡è¯·æ±‚
   * @param configId æ¨¡å‹é…ç½®ID
   * @returns æ‰¹é‡å“åº”
   */
  async batchMessages(
    requests: Array<{
      message: string;
      systemPrompt?: string;
    }>,
    configId: string
  ): Promise<string[]> {
    const model = await this.getModel(configId);
    
    const messageBatches = requests.map(req => [
      ...(req.systemPrompt ? [new SystemMessage(req.systemPrompt)] : []),
      new HumanMessage(req.message)
    ]);
    
    const responses = await model.batch(messageBatches);
    return responses.map(response => response.content as string);
  }

  /**
   * æµ‹è¯•æ¨¡å‹è¿æ¥
   * @param configId æ¨¡å‹é…ç½®ID
   * @returns æµ‹è¯•ç»“æœ
   */
  async testModel(configId: string): Promise<{ success: boolean; error?: string; responseTime?: number }> {
    try {
      const startTime = Date.now();
      await this.sendMessage('Hello', configId);
      const responseTime = Date.now() - startTime;
      
      return {
        success: true,
        responseTime
      };
    } catch (error) {
      return {
        success: false,
        error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'
      };
    }
  }

  /**
   * è·å–æˆ–åˆ›å»ºæ¨¡å‹å®ä¾‹
   * @param configId é…ç½®ID
   * @returns æ¨¡å‹å®ä¾‹
   */
  private async getModel(configId: string): Promise<BaseChatModel> {
    if (!this.modelCache.has(configId)) {
      const config = await this.getConfig(configId);
      const model = LangChainModelFactory.createChatModel(config);
      this.modelCache.set(configId, model);
    }
    return this.modelCache.get(configId)!;
  }

  /**
   * è·å–é…ç½®
   * @param configId é…ç½®ID
   * @returns é…ç½®å®ä½“
   */
  private async getConfig(configId: string): Promise<ModelConfigEntity> {
    // å…ˆæ£€æŸ¥ç¼“å­˜
    if (this.configCache.has(configId)) {
      return this.configCache.get(configId)!;
    }

    // å¦‚æœæ²¡æœ‰é…ç½®æœåŠ¡ï¼ŒæŠ›å‡ºé”™è¯¯
    if (!this.configService) {
      throw new Error(`é…ç½®æœåŠ¡æœªæ³¨å…¥ï¼Œæ— æ³•è·å–é…ç½®: ${configId}`);
    }

    // ä»é…ç½®æœåŠ¡è·å–
    const config = await this.configService.getConfigById(configId);
    if (!config) {
      throw new Error(`é…ç½®ä¸å­˜åœ¨: ${configId}`);
    }

    // ç¼“å­˜é…ç½®
    this.configCache.set(configId, config);
    return config;
  }

  /**
   * è®¾ç½®é…ç½®ï¼ˆç”¨äºæµ‹è¯•æˆ–æ‰‹åŠ¨è®¾ç½®ï¼‰
   * @param configId é…ç½®ID
   * @param config é…ç½®å®ä½“
   */
  setConfig(configId: string, config: ModelConfigEntity): void {
    this.configCache.set(configId, config);
    // æ¸…é™¤å¯¹åº”çš„æ¨¡å‹ç¼“å­˜ï¼Œå¼ºåˆ¶é‡æ–°åˆ›å»º
    this.modelCache.delete(configId);
  }

  /**
   * æ¸…é™¤ç¼“å­˜
   * @param configId å¯é€‰çš„é…ç½®IDï¼Œå¦‚æœä¸æä¾›åˆ™æ¸…é™¤æ‰€æœ‰ç¼“å­˜
   */
  clearCache(configId?: string): void {
    if (configId) {
      this.modelCache.delete(configId);
      this.configCache.delete(configId);
    } else {
      this.modelCache.clear();
      this.configCache.clear();
    }
  }

  /**
   * è·å–Geminiå¯ç”¨æ¨¡å‹åˆ—è¡¨
   * @param config æ¨¡å‹é…ç½®
   * @returns Geminiæ¨¡å‹åˆ—è¡¨
   */
  private async getGeminiModels(config: ModelConfigEntity): Promise<string[]> {
    try {
      const baseURL = config.baseURL || 'https://generativelanguage.googleapis.com';
      const url = `${baseURL}/v1beta/models?key=${config.apiKey}`;

      console.log(`ğŸ” è·å–Geminiæ¨¡å‹åˆ—è¡¨: ${url.replace(config.apiKey, '***')}`);

      const response = await fetch(url);

      if (!response.ok) {
        const errorText = await response.text();
        console.error(`âŒ Geminiæ¨¡å‹åˆ—è¡¨è·å–å¤±è´¥ (${response.status}): ${errorText}`);

        // æŠ›å‡ºè¯¦ç»†é”™è¯¯è€Œä¸æ˜¯é™çº§ï¼Œè®©ç”¨æˆ·çŸ¥é“å…·ä½“é—®é¢˜
        throw new Error(`Gemini APIè°ƒç”¨å¤±è´¥ (${response.status}): ${errorText.substring(0, 200)}`);
      }

      const data = await response.json();
      console.log('ğŸ” Gemini APIåŸå§‹å“åº”:', JSON.stringify(data, null, 2));

      const models = this.parseGeminiModelsResponse(data);

      if (models.length === 0) {
        console.error('âŒ è§£æåçš„Geminiæ¨¡å‹åˆ—è¡¨ä¸ºç©º');
        console.log('åŸå§‹æ•°æ®ç»“æ„:', data);
        throw new Error('Gemini APIè¿”å›äº†æ•°æ®ä½†è§£æåæ¨¡å‹åˆ—è¡¨ä¸ºç©ºï¼Œå¯èƒ½æ˜¯APIæ ¼å¼å˜åŒ–');
      }

      console.log(`âœ… æˆåŠŸè·å– ${models.length} ä¸ªGeminiæ¨¡å‹:`, models);
      return models;

    } catch (error) {
      console.error('âŒ Geminiæ¨¡å‹åˆ—è¡¨è·å–å¼‚å¸¸:', error);
      // ä¸å†è‡ªåŠ¨é™çº§ï¼ŒæŠ›å‡ºé”™è¯¯è®©ç”¨æˆ·çŸ¥é“å…·ä½“é—®é¢˜
      throw error instanceof Error ? error : new Error(`Geminiæ¨¡å‹è·å–å¤±è´¥: ${error}`);
    }
  }

  /**
   * è·å–OpenAIå¯ç”¨æ¨¡å‹åˆ—è¡¨
   * @param config æ¨¡å‹é…ç½®
   * @returns OpenAIæ¨¡å‹åˆ—è¡¨
   */
  private async getOpenAIModels(config: ModelConfigEntity): Promise<string[]> {
    try {
      const baseURL = config.baseURL || 'https://api.openai.com/v1';
      const url = `${baseURL}/models`;

      const response = await fetch(url, {
        headers: {
          'Authorization': `Bearer ${config.apiKey}`
        }
      });

      if (!response.ok) {
        console.warn(`OpenAIæ¨¡å‹åˆ—è¡¨è·å–å¤±è´¥ (${response.status})ï¼Œä½¿ç”¨é¢„å®šä¹‰åˆ—è¡¨`);
        return this.getDefaultOpenAIModels();
      }

      const data = await response.json();
      const models = this.parseOpenAIModelsResponse(data);

      if (models.length === 0) {
        console.warn('æœªè·å–åˆ°OpenAIæ¨¡å‹ï¼Œä½¿ç”¨é¢„å®šä¹‰åˆ—è¡¨');
        return this.getDefaultOpenAIModels();
      }

      console.log(`âœ… æˆåŠŸè·å– ${models.length} ä¸ªOpenAIæ¨¡å‹`);
      return models;

    } catch (error) {
      console.warn('OpenAIæ¨¡å‹åˆ—è¡¨è·å–å¼‚å¸¸ï¼Œä½¿ç”¨é¢„å®šä¹‰åˆ—è¡¨:', error);
      return this.getDefaultOpenAIModels();
    }
  }

  /**
   * è§£æGeminiæ¨¡å‹å“åº”
   * @param data APIå“åº”æ•°æ®
   * @returns æ¨¡å‹åç§°åˆ—è¡¨
   */
  private parseGeminiModelsResponse(data: any): string[] {
    try {
      if (data.models && Array.isArray(data.models)) {
        const models = data.models
          .map((model: any) => {
            // Gemini APIè¿”å›æ ¼å¼: "models/gemini-1.5-pro"
            const modelName = model.name || model.id;
            if (typeof modelName === 'string' && modelName.startsWith('models/')) {
              return {
                name: modelName.replace('models/', ''),
                displayName: model.displayName || modelName.replace('models/', ''),
                description: model.description || '',
                inputTokenLimit: model.inputTokenLimit || 0,
                outputTokenLimit: model.outputTokenLimit || 0,
                supportedMethods: model.supportedGenerationMethods || []
              };
            }
            return null;
          })
          .filter((model: any) => {
            // è¿‡æ»¤å‡ºæœ‰æ•ˆçš„GeminièŠå¤©æ¨¡å‹
            if (!model || !model.name) {
              console.log('âŒ è·³è¿‡æ— æ•ˆæ¨¡å‹:', model);
              return false;
            }

            const name = model.name.toLowerCase();
            const isGeminiModel = name.includes('gemini') || name.includes('bison') || name.includes('chat-bison');
            const isChatModel = model.supportedMethods.includes('generateContent') ||
                               name.includes('chat') ||
                               name.includes('pro') ||
                               name.includes('flash') ||
                               name.includes('gemini'); // æ”¾å®½æ¡ä»¶ï¼šåŒ…å«geminiçš„éƒ½è®¤ä¸ºæ˜¯èŠå¤©æ¨¡å‹
            const isNotEmbedding = !name.includes('embedding') &&
                                  !name.includes('aqa') &&
                                  !name.includes('text-bison') &&
                                  !name.includes('imagen');

            const shouldInclude = isGeminiModel && isChatModel && isNotEmbedding;

            console.log(`ğŸ” æ¨¡å‹è¿‡æ»¤: ${model.name}`, {
              isGeminiModel,
              isChatModel,
              isNotEmbedding,
              shouldInclude,
              supportedMethods: model.supportedMethods
            });

            return shouldInclude;
          })
          .sort((a: any, b: any) => {
            // æ’åºï¼š2.5ç‰ˆæœ¬ > 2.0ç‰ˆæœ¬ > 1.5ç‰ˆæœ¬ > 1.0ç‰ˆæœ¬ï¼ŒPro > Flash > å…¶ä»–
            const getVersionScore = (name: string) => {
              if (name.includes('2.5')) return 250;
              if (name.includes('2.0')) return 200;
              if (name.includes('1.5')) return 150;
              if (name.includes('1.0')) return 100;
              return 50;
            };

            const getTypeScore = (name: string) => {
              if (name.includes('pro')) return 30;
              if (name.includes('flash')) return 20;
              return 10;
            };

            const scoreA = getVersionScore(a.name) + getTypeScore(a.name);
            const scoreB = getVersionScore(b.name) + getTypeScore(b.name);

            return scoreB - scoreA; // é™åºæ’åˆ—
          })
          .map((model: any) => model.name);

        console.log(`âœ… è§£æåˆ° ${models.length} ä¸ªGeminièŠå¤©æ¨¡å‹:`, models.slice(0, 5));
        return models;
      }
    } catch (error) {
      console.warn('è§£æGeminiæ¨¡å‹å“åº”å¤±è´¥:', error);
    }
    return [];
  }

  /**
   * è§£æOpenAIæ¨¡å‹å“åº”
   * @param data APIå“åº”æ•°æ®
   * @returns æ¨¡å‹åç§°åˆ—è¡¨
   */
  private parseOpenAIModelsResponse(data: any): string[] {
    try {
      if (data.data && Array.isArray(data.data)) {
        return data.data
          .map((model: any) => model.id)
          .filter((id: string) => {
            if (!id) return false;
            
            // æ’é™¤éèŠå¤©æ¨¡å‹
            const excludePatterns = [
              'text-embedding',    // embeddingæ¨¡å‹
              'tts-',             // æ–‡æœ¬è½¬è¯­éŸ³æ¨¡å‹
              'whisper',          // è¯­éŸ³è¯†åˆ«æ¨¡å‹
              'dall-e',           // å›¾åƒç”Ÿæˆæ¨¡å‹
              'davinci-002',      // æ—§ç‰ˆæœ¬æ¨¡å‹
              'text-ada',         // æ—§ç‰ˆæœ¬embedding
              'transcribe',       // è½¬å½•æ¨¡å‹
              'image-1'           // å›¾åƒå¤„ç†æ¨¡å‹
            ];
            
            // å¦‚æœåŒ…å«æ’é™¤æ¨¡å¼ï¼Œè·³è¿‡
            if (excludePatterns.some(pattern => id.includes(pattern))) {
              return false;
            }
            
            // åŒ…å«èŠå¤©æ¨¡å‹æ¨¡å¼
            const includePatterns = [
              'gpt',              // GPTç³»åˆ—
              'o1',               // O1ç³»åˆ—
              'o3',               // O3ç³»åˆ—
              'o4',               // O4ç³»åˆ—
              'chatgpt',          // ChatGPTç³»åˆ—
              'claude',           // Claudeç³»åˆ—
              'gemini',           // Geminiç³»åˆ—
              'deepseek',         // DeepSeekç³»åˆ—
              'grok',             // Grokç³»åˆ—
              'qwen',             // Qwenç³»åˆ—
              'kimi'              // Kimiç³»åˆ—
            ];
            
            // åŒ…å«ä»»æ„ä¸€ä¸ªæ¨¡å¼å³å¯
            return includePatterns.some(pattern => id.includes(pattern));
          })
          .sort();
      }
    } catch (error) {
      console.warn('è§£æOpenAIæ¨¡å‹å“åº”å¤±è´¥:', error);
    }
    return [];
  }



  /**
   * è·å–é»˜è®¤OpenAIæ¨¡å‹åˆ—è¡¨
   * @returns é¢„å®šä¹‰çš„OpenAIæ¨¡å‹åˆ—è¡¨
   */
  private getDefaultOpenAIModels(): string[] {
    return [
      'gpt-4o',
      'gpt-4o-mini',
      'gpt-4-turbo',
      'gpt-4',
      'gpt-3.5-turbo',
      'o1-preview',
      'o1-mini'
    ];
  }

  /**
   * è·å–è‡ªå®šä¹‰æä¾›å•†çš„æ¨¡å‹åˆ—è¡¨
   * @param config æ¨¡å‹é…ç½®
   * @returns å¯ç”¨æ¨¡å‹åˆ—è¡¨
   */
  private async getCustomProviderModels(config: ModelConfigEntity): Promise<string[]> {
    try {
      // å¯¹äºè‡ªå®šä¹‰æä¾›å•†ï¼Œå°è¯•é€šè¿‡é€šç”¨APIè·å–æ¨¡å‹åˆ—è¡¨
      // å¤§å¤šæ•°OpenAIå…¼å®¹çš„APIéƒ½æ”¯æŒ /v1/models ç«¯ç‚¹
      const baseURL = config.baseURL.replace(/\/+$/, ''); // ç§»é™¤æœ«å°¾çš„æ–œæ 
      const modelsURL = `${baseURL}/models`;

      console.log(`ğŸ” è·å–è‡ªå®šä¹‰æä¾›å•†æ¨¡å‹åˆ—è¡¨: ${modelsURL}`);

      const response = await fetch(modelsURL, {
        method: 'GET',
        headers: {
          'Authorization': `Bearer ${config.apiKey}`,
          'Content-Type': 'application/json'
        }
      });

      if (!response.ok) {
        console.warn(`è·å–è‡ªå®šä¹‰æä¾›å•†æ¨¡å‹åˆ—è¡¨å¤±è´¥: ${response.status} ${response.statusText}`);
        return this.getDefaultCustomModels();
      }

      const data = await response.json();
      console.log('ğŸ” è‡ªå®šä¹‰æä¾›å•†APIåŸå§‹å“åº”:', JSON.stringify(data, null, 2));

      if (data.data && Array.isArray(data.data)) {
        const models = data.data
          .map((model: any) => model.id)
          .filter((id: string) => id && typeof id === 'string')
          .sort();

        console.log(`âœ… æˆåŠŸè·å– ${models.length} ä¸ªè‡ªå®šä¹‰æä¾›å•†æ¨¡å‹:`, models);
        return models.length > 0 ? models : this.getDefaultCustomModels();
      }
    } catch (error) {
      console.warn('è·å–è‡ªå®šä¹‰æä¾›å•†æ¨¡å‹åˆ—è¡¨æ—¶å‡ºé”™:', error);
    }

    return this.getDefaultCustomModels();
  }

  /**
   * è·å–é»˜è®¤çš„è‡ªå®šä¹‰æ¨¡å‹åˆ—è¡¨
   * @returns é¢„å®šä¹‰çš„é€šç”¨æ¨¡å‹åˆ—è¡¨
   */
  private getDefaultCustomModels(): string[] {
    return [
      // Moonshot AI æ¨¡å‹
      'kimi-k2-0711-preview',
      'moonshot-v1-8k',
      'moonshot-v1-32k',
      'moonshot-v1-128k',
      // é€šç”¨OpenAIå…¼å®¹æ¨¡å‹
      'gpt-3.5-turbo',
      'gpt-4',
      'gpt-4-turbo',
      'gpt-4o',
      'gpt-4o-mini',
      // å…¶ä»–å¸¸è§ç¬¬ä¸‰æ–¹æ¨¡å‹
      'deepseek-chat',
      'deepseek-coder',
      'qwen-turbo',
      'qwen-plus',
      'chatglm-6b',
      'chatglm2-6b',
      'llama-2-7b-chat',
      'llama-2-13b-chat',
      'mistral-7b-instruct',
      'custom-model'
    ];
  }

  /**
   * è·å–ç³»ç»Ÿæç¤ºè¯æä¾›å™¨
   * @returns ç³»ç»Ÿæç¤ºè¯æä¾›å™¨å®ä¾‹
   */
  getSystemPromptProvider(): ISystemPromptProvider {
    return this.promptProvider;
  }

  // ==================== MCPå·¥å…·é›†æˆæ–¹æ³• ====================


  /**
   * ä½¿ç”¨MCPå·¥å…·å¢å¼ºçš„æ¶ˆæ¯å‘é€ï¼ˆæ ‡å‡†LangChainæ–¹å¼ï¼‰
   * @param message ç”¨æˆ·æ¶ˆæ¯
   * @param config æ¨¡å‹é…ç½®
   * @param systemPrompt å¯é€‰çš„ç³»ç»Ÿæç¤ºè¯
   * @param enableMCPTools æ˜¯å¦å¯ç”¨MCPå·¥å…·
   * @returns æ¨¡å‹å“åº”å’Œå·¥å…·è°ƒç”¨ä¿¡æ¯
   */
  async sendMessageWithMCPTools(
    message: string,
    config: ModelConfigEntity,
    systemPrompt?: string,
    enableMCPTools: boolean = true
  ): Promise<{
    content: string;
    toolCalls?: any[];
    hasToolCalls: boolean;
    error?: boolean;
  }> {
    // å¦‚æœæ²¡æœ‰å¯ç”¨MCPå·¥å…·æˆ–æ²¡æœ‰MCPæœåŠ¡ï¼Œä½¿ç”¨æ ‡å‡†æ–¹å¼
    if (!enableMCPTools || !this.mcpService) {
      const content = await this.sendMessageWithConfig(message, config, systemPrompt);
      return {
        content,
        hasToolCalls: false
      };
    }

    try {
      // è·å–å¯ç”¨çš„MCPå·¥å…·
      const mcpTools = await this.mcpService.getAllTools();
      log.info(`ğŸ”§ [LangChainå·¥å…·é›†æˆ] è·å–åˆ° ${mcpTools.length} ä¸ªMCPå·¥å…·`);

      if (mcpTools.length === 0) {
        // æ²¡æœ‰å¯ç”¨å·¥å…·ï¼Œä½¿ç”¨æ™®é€šæ¨¡å¼
        const content = await this.sendMessageWithConfig(message, config, systemPrompt);
        return {
          content,
          hasToolCalls: false
        };
      }

      // åˆ›å»ºæ¨¡å‹å®ä¾‹
      const model = LangChainModelFactory.createChatModel(config);
      
      // æ„å»ºæ¶ˆæ¯ï¼ŒåŒ…å«å·¥å…·ä¿¡æ¯çš„ç³»ç»Ÿæç¤º
      let finalSystemPrompt = this.promptProvider.buildSystemPrompt();
      
      // æ·»åŠ MCPå·¥å…·ä¿¡æ¯åˆ°ç³»ç»Ÿæç¤º
      const toolsDescription = mcpTools.map(tool => 
        `- ${tool.name}: ${tool.description || 'æ— æè¿°'}`
      ).join('\n');
      
      const mcpSystemPrompt = `\n\nå¯ç”¨å·¥å…·åˆ—è¡¨:\n${toolsDescription}\n\nğŸ”§ å·¥å…·è°ƒç”¨è§„åˆ™ï¼š
1. å½“ç”¨æˆ·æ˜ç¡®è¦æ±‚æ‰§è¡ŒæŸä¸ªå·¥å…·æˆ–å‘½ä»¤æ—¶ï¼Œå¿…é¡»ç«‹å³è°ƒç”¨ç›¸åº”å·¥å…·
2. å½“ç”¨æˆ·è¯¢é—®å¯ç”¨è§’è‰²ã€å·¥å…·åˆ—è¡¨ç­‰ä¿¡æ¯æ—¶ï¼Œä½¿ç”¨ promptx_welcome å·¥å…·
3. å½“ç”¨æˆ·è¦æ±‚æ¿€æ´»è§’è‰²æ—¶ï¼Œä½¿ç”¨ promptx_action å·¥å…·
4. å·¥å…·è°ƒç”¨æ ¼å¼ï¼š[TOOL_CALL:å·¥å…·åç§°:å‚æ•°JSON]
5. å…ˆæ‰§è¡Œå·¥å…·ï¼Œå†åŸºäºå·¥å…·ç»“æœå›å¤ç”¨æˆ·

ç¤ºä¾‹ï¼š
- ç”¨æˆ·ï¼š"å¸®æˆ‘æ‰§è¡Œwelcomeå‘½ä»¤" â†’ ç«‹å³è¾“å‡ºï¼š[TOOL_CALL:promptx_welcome:{}]
- ç”¨æˆ·ï¼š"æ˜¾ç¤ºå¯ç”¨è§’è‰²" â†’ ç«‹å³è¾“å‡ºï¼š[TOOL_CALL:promptx_welcome:{}]
- ç”¨æˆ·ï¼š"æ¿€æ´»architectè§’è‰²" â†’ ç«‹å³è¾“å‡ºï¼š[TOOL_CALL:promptx_action:{"role":"architect"}]`;
      
      if (systemPrompt) {
        finalSystemPrompt = finalSystemPrompt ? 
          `${finalSystemPrompt}\n\n${systemPrompt}${mcpSystemPrompt}` : 
          `${systemPrompt}${mcpSystemPrompt}`;
      } else {
        finalSystemPrompt = finalSystemPrompt ? 
          `${finalSystemPrompt}${mcpSystemPrompt}` : 
          mcpSystemPrompt;
      }

      const messages: BaseMessage[] = [
        ...(finalSystemPrompt ? [new SystemMessage(finalSystemPrompt)] : []),
        new HumanMessage(message)
      ];

      // è°ƒç”¨æ¨¡å‹
      log.info(`ğŸ¤– [LangChainå·¥å…·é›†æˆ] è°ƒç”¨æ¨¡å‹ï¼Œå¯ç”¨å·¥å…·æ•°é‡: ${mcpTools.length}`);
      const response = await model.invoke(messages);
      const content = response.content as string;

      // æ£€æŸ¥å“åº”ä¸­æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨
      const toolCallPattern = /\[TOOL_CALL:([^:]+):([^\]]+)\]/g;
      const toolCalls: any[] = [];
      let processedContent = content;
      let match;

      while ((match = toolCallPattern.exec(content)) !== null) {
        const [fullMatch, toolName, argsJson] = match;
        
        try {
          const args = JSON.parse(argsJson);
          const mcpTool = mcpTools.find(t => t.name === toolName);
          
          if (mcpTool) {
            log.info(`ğŸ”§ [LangChainå·¥å…·é›†æˆ] æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: ${toolName}`);
            
            // æ‰§è¡ŒMCPå·¥å…·è°ƒç”¨
            const toolResponse = await this.mcpService!.callTool({
              serverId: mcpTool.serverId,
              toolName: mcpTool.name,
              arguments: args
            });

            const toolResult = toolResponse.success ? 
              (typeof toolResponse.result === 'string' ? toolResponse.result : JSON.stringify(toolResponse.result)) :
              `å·¥å…·æ‰§è¡Œå¤±è´¥: ${toolResponse.error}`;

            toolCalls.push({
              id: `tool_${Date.now()}_${toolCalls.length}`,
              name: toolName,
              args: args,
              result: toolResult
            });

            // æ›¿æ¢å·¥å…·è°ƒç”¨ä¸ºç»“æœ
            processedContent = processedContent.replace(fullMatch, `[å·¥å…·æ‰§è¡Œç»“æœ: ${toolResult}]`);
          }
        } catch (error) {
          log.error(`âŒ [LangChainå·¥å…·é›†æˆ] å·¥å…·è°ƒç”¨è§£æå¤±è´¥: ${toolName}`, error);
          processedContent = processedContent.replace(fullMatch, `[å·¥å…·è°ƒç”¨å¤±è´¥: å‚æ•°è§£æé”™è¯¯]`);
        }
      }

      const hasToolCalls = toolCalls.length > 0;
      log.info(`ğŸ“Š [LangChainå·¥å…·é›†æˆ] å“åº”åŒ…å«å·¥å…·è°ƒç”¨: ${hasToolCalls}, è°ƒç”¨æ•°é‡: ${toolCalls.length}`);

      return {
        content: processedContent,
        toolCalls: hasToolCalls ? toolCalls : undefined,
        hasToolCalls
      };

    } catch (error) {
      log.error('âŒ [LangChainå·¥å…·é›†æˆ] MCPå·¥å…·å¢å¼ºæ¶ˆæ¯å‘é€å¤±è´¥:', error);
      
      // æ£€æŸ¥æ˜¯å¦æ˜¯APIç›¸å…³é”™è¯¯ï¼Œå¦‚æœæ˜¯åˆ™è¿”å›ç”¨æˆ·å‹å¥½çš„é”™è¯¯ä¿¡æ¯
      const errorMessage = error instanceof Error ? error.message : String(error);
      if (errorMessage.includes('ä½™é¢') || errorMessage.includes('balance') || 
          errorMessage.includes('401') || errorMessage.includes('403') ||
          errorMessage.includes('ApiKey') || errorMessage.includes('api key')) {
        return {
          content: `âš ï¸ **APIæœåŠ¡å¼‚å¸¸**\n\næŠ±æ­‰ï¼Œå½“å‰AIæœåŠ¡é‡åˆ°ä»¥ä¸‹é—®é¢˜ï¼š\n\n${errorMessage.includes('ä½™é¢') || errorMessage.includes('balance') ? 'ğŸ’³ **è´¦æˆ·ä½™é¢ä¸è¶³**ï¼šAPIå¯†é’¥ä½™é¢å·²ç”¨å®Œï¼Œè¯·è”ç³»ç®¡ç†å‘˜å……å€¼æˆ–æ›´æ–°å¯†é’¥ã€‚' : 'ğŸ”‘ **APIå¯†é’¥é—®é¢˜**ï¼šå½“å‰å¯†é’¥æ— æ•ˆæˆ–å·²è¿‡æœŸï¼Œè¯·æ£€æŸ¥APIé…ç½®ã€‚'}\n\nğŸ› ï¸ **ä¸´æ—¶è§£å†³æ–¹æ¡ˆ**ï¼š\n- è¯·åœ¨è®¾ç½®ä¸­æ›´æ–°æœ‰æ•ˆçš„APIå¯†é’¥\n- æˆ–è”ç³»ç®¡ç†å‘˜å¤„ç†APIé…ç½®é—®é¢˜\n- æˆ–åˆ‡æ¢åˆ°å…¶ä»–å¯ç”¨çš„AIæ¨¡å‹\n\nğŸ“ **æŠ€æœ¯è¯¦æƒ…ï¼ˆä¾›å¼€å‘è€…å‚è€ƒï¼‰**ï¼š\n\`\`\`\n${errorMessage}\n\`\`\``,
          hasToolCalls: false,
          error: true // æ ‡è®°ä¸ºé”™è¯¯å“åº”
        };
      }
      
      // å…¶ä»–é”™è¯¯é™çº§åˆ°æ™®é€šæ¨¡å¼
      try {
        const content = await this.sendMessageWithConfig(message, config, systemPrompt);
        return {
          content: `âš ï¸ **MCPå·¥å…·æœåŠ¡æš‚æ—¶ä¸å¯ç”¨**\n\n${content}\n\n---\n*æ³¨ï¼šå½“å‰ä»¥æ™®é€šæ¨¡å¼å›å¤ï¼ŒMCPå·¥å…·åŠŸèƒ½æš‚æ—¶å…³é—­ã€‚å¦‚éœ€ä½¿ç”¨ä¸“ä¸šå·¥å…·ï¼Œè¯·è”ç³»ç®¡ç†å‘˜æ£€æŸ¥æœåŠ¡çŠ¶æ€ã€‚*`,
          hasToolCalls: false,
          error: false
        };
      } catch (fallbackError) {
        log.error('âŒ [LangChainé™çº§] æ™®é€šæ¨¡å¼ä¹Ÿå¤±è´¥:', fallbackError);
        return {
          content: `âŒ **AIæœåŠ¡å®Œå…¨ä¸å¯ç”¨**\n\næŠ±æ­‰ï¼Œå½“å‰AIæœåŠ¡é‡åˆ°ä¸¥é‡é—®é¢˜ï¼Œæ— æ³•æ­£å¸¸å“åº”ã€‚è¯·è”ç³»ç®¡ç†å‘˜æ£€æŸ¥ï¼š\n\n1. APIå¯†é’¥é…ç½®\n2. ç½‘ç»œè¿æ¥çŠ¶æ€\n3. æœåŠ¡å™¨çŠ¶æ€\n\n**é”™è¯¯è¯¦æƒ…**ï¼š\n\`\`\`\n${String(fallbackError)}\n\`\`\``,
          hasToolCalls: false,
          error: true
        };
      }
    }
  }

  /**
   * è®¾ç½®MCPæœåŠ¡ï¼ˆç”¨äºåç»­æ³¨å…¥ï¼‰
   * @param mcpService MCPé›†æˆæœåŠ¡å®ä¾‹
   */
  setMCPService(mcpService: MCPIntegrationServiceInterface): void {
    this.mcpService = mcpService;
    
    // åŒæ­¥åˆ°å¢å¼ºæç¤ºè¯æä¾›å™¨
    if (this.promptProvider === enhancedSystemPromptProvider) {
      // è¿™é‡Œå¯ä»¥é€šçŸ¥å·¥å…·çŠ¶æ€å˜åŒ–ï¼Œä½†éœ€è¦å·¥å…·åˆ—è¡¨
      log.info('ğŸ”§ [LangChainæœåŠ¡] MCPæœåŠ¡å·²æ›´æ–°');
    }
  }

  // ==================== DeeChatæ™ºèƒ½å¯¹è¯æ–¹æ³• ====================

  /**
   * ğŸ§  DeeChatæ™ºèƒ½æ¶ˆæ¯å¤„ç†
   * é›†æˆæ„å›¾è¯†åˆ«ã€ä¸Šä¸‹æ–‡åˆ†æå’Œç”¨æˆ·è‡ªä¸»æƒä¿æŠ¤çš„å®Œæ•´å¯¹è¯ç³»ç»Ÿ
   */
  async sendIntelligentMessage(
    userMessage: string,
    config: ModelConfigEntity,
    sessionInfo: {
      sessionId: string;
      userId?: string;
      currentFeature: DeeChatFeature;
      activeRole?: string;
    },
    options?: {
      systemPrompt?: string;
      enableMCPTools?: boolean;
      enableIntentAnalysis?: boolean;
    }
  ): Promise<{
    content: string;
    context: ConversationContext;
    toolCalls?: any[];
    hasToolCalls: boolean;
    shouldRemember: boolean;
    suggestedActions: string[];
    error?: boolean;
    insights?: {
      intentConfidence: number;
      emotionalState: string;
      suggestedNextSteps: string[];
    };
  }> {
    const enableIntentAnalysis = options?.enableIntentAnalysis ?? this.isIntentSystemEnabled;
    const enableMCPTools = options?.enableMCPTools ?? true;

    try {
      // å‡†å¤‡ä¼šè¯ä¿¡æ¯
      const mcpTools = enableMCPTools && this.mcpService ? 
        await this.mcpService.getAllTools() : [];
      
      const fullSessionInfo = {
        ...sessionInfo,
        availableTools: mcpTools.map(tool => tool.name)
      };

      // å¦‚æœå¯ç”¨æ„å›¾åˆ†æï¼Œä½¿ç”¨å¢å¼ºçš„æç¤ºè¯ç³»ç»Ÿ
      if (enableIntentAnalysis && this.promptProvider === enhancedSystemPromptProvider) {
        // ä½¿ç”¨DeeChatç‰¹æœ‰çš„æ™ºèƒ½æ¶ˆæ¯å¤„ç†
        const analysisResult = await enhancedSystemPromptProvider.processUserMessage(
          userMessage, 
          fullSessionInfo
        );

        // ä½¿ç”¨å¢å¼ºçš„ç³»ç»Ÿæç¤ºè¯å‘é€æ¶ˆæ¯ï¼ˆåŒ…å«æ„å›¾åˆ†æç»“æœï¼‰
        const response = await this.sendMessageWithMCPTools(
          userMessage,
          config,
          options?.systemPrompt || analysisResult.enhancedPrompt,
          enableMCPTools
        );

        // æ„å»ºæ´å¯Ÿä¿¡æ¯
        const insights = {
          intentConfidence: analysisResult.context.confidence,
          emotionalState: this.analyzeEmotionalState(analysisResult.context),
          suggestedNextSteps: analysisResult.suggestedActions
        };

        log.info(`ğŸ§  [æ™ºèƒ½å¯¹è¯] æ„å›¾: ${analysisResult.context.detectedIntent}, ` +
                 `ç½®ä¿¡åº¦: ${(analysisResult.context.confidence * 100).toFixed(0)}%, ` +
                 `å·¥å…·è°ƒç”¨: ${response.hasToolCalls ? 'æ˜¯' : 'å¦'}`);

        return {
          content: response.content,
          context: analysisResult.context,
          toolCalls: response.toolCalls,
          hasToolCalls: response.hasToolCalls,
          shouldRemember: analysisResult.shouldRemember,
          suggestedActions: analysisResult.suggestedActions,
          error: response.error,
          insights
        };
      } else {
        // å›é€€åˆ°æ ‡å‡†æ¨¡å¼
        log.info('ğŸ“ [æ ‡å‡†å¯¹è¯] ä½¿ç”¨åŸºç¡€LLMæ¨¡å¼');
        
        const response = await this.sendMessageWithMCPTools(
          userMessage,
          config,
          options?.systemPrompt,
          enableMCPTools
        );

        // åˆ›å»ºåŸºç¡€ä¸Šä¸‹æ–‡
        const basicContext: ConversationContext = {
          sessionId: sessionInfo.sessionId,
          timestamp: new Date(),
          userMessage,
          detectedIntent: 'unclear' as any,
          confidence: 0.5,
          currentFeature: sessionInfo.currentFeature,
          activeRole: sessionInfo.activeRole,
          availableTools: mcpTools.map(tool => tool.name),
          memoryScore: 1,
          shouldRemember: false,
          planNeedsUpdate: false,
          suggestedActions: ['ç»§ç»­å¯¹è¯'],
          isCorrection: false,
          isFrustration: false,
          requiresTools: response.hasToolCalls
        };

        return {
          content: response.content,
          context: basicContext,
          toolCalls: response.toolCalls,
          hasToolCalls: response.hasToolCalls,
          shouldRemember: false,
          suggestedActions: ['ç»§ç»­å¯¹è¯'],
          error: response.error,
          insights: {
            intentConfidence: 0.5,
            emotionalState: 'ä¸­æ€§',
            suggestedNextSteps: ['ç»§ç»­å¯¹è¯']
          }
        };
      }
    } catch (error) {
      log.error('âŒ [æ™ºèƒ½å¯¹è¯] å¤„ç†å¤±è´¥:', error);
      
      // åˆ›å»ºé”™è¯¯ä¸Šä¸‹æ–‡
      const errorContext: ConversationContext = {
        sessionId: sessionInfo.sessionId,
        timestamp: new Date(),
        userMessage,
        detectedIntent: 'unclear' as any,
        confidence: 0.1,
        currentFeature: sessionInfo.currentFeature,
        activeRole: sessionInfo.activeRole,
        availableTools: [],
        memoryScore: 1,
        shouldRemember: false,
        planNeedsUpdate: false,
        suggestedActions: ['é‡è¯•å¯¹è¯', 'æ£€æŸ¥ç³»ç»ŸçŠ¶æ€'],
        isCorrection: false,
        isFrustration: false,
        requiresTools: false
      };

      return {
        content: `âŒ **å¯¹è¯å¤„ç†å¤±è´¥**\n\næŠ±æ­‰ï¼Œç³»ç»Ÿé‡åˆ°äº†é—®é¢˜ï¼š${error instanceof Error ? error.message : String(error)}\n\nè¯·ç¨åé‡è¯•æˆ–è”ç³»æŠ€æœ¯æ”¯æŒã€‚`,
        context: errorContext,
        hasToolCalls: false,
        shouldRemember: false,
        suggestedActions: ['é‡è¯•å¯¹è¯', 'æ£€æŸ¥ç³»ç»ŸçŠ¶æ€'],
        error: true,
        insights: {
          intentConfidence: 0.1,
          emotionalState: 'é”™è¯¯',
          suggestedNextSteps: ['é‡è¯•å¯¹è¯', 'æ£€æŸ¥ç³»ç»ŸçŠ¶æ€']
        }
      };
    }
  }

  /**
   * ğŸ­ æ›´æ–°DeeChatä¼šè¯ä¸Šä¸‹æ–‡
   */
  updateSessionContext(
    feature: DeeChatFeature,
    activeRole?: string,
    availableTools?: string[]
  ): void {
    // æ›´æ–°å¢å¼ºæç¤ºè¯æä¾›å™¨çš„çŠ¶æ€
    if (this.promptProvider === enhancedSystemPromptProvider) {
      enhancedSystemPromptProvider.setFeatureContext(feature);
      
      if (activeRole) {
        enhancedSystemPromptProvider.setPromptXRole(activeRole);
      }
      
      if (availableTools) {
        enhancedSystemPromptProvider.updateMCPToolStatus(availableTools);
      }
      
      log.info(`ğŸ­ [ä¼šè¯ä¸Šä¸‹æ–‡] åŠŸèƒ½: ${feature}, è§’è‰²: ${activeRole || 'æ— '}, å·¥å…·: ${availableTools?.length || 0}ä¸ª`);
    }
  }

  /**
   * ğŸ“Š è·å–æ™ºèƒ½å¯¹è¯ç»Ÿè®¡
   */
  getIntelligentChatStats(): {
    enabled: boolean;
    currentSession?: string;
    systemStats: any;
    recommendations: string[];
  } {
    if (this.promptProvider === enhancedSystemPromptProvider) {
      const stats = enhancedSystemPromptProvider.getDeeChatStats();
      const insights = enhancedSystemPromptProvider.getConversationInsights();
      
      return {
        enabled: this.isIntentSystemEnabled,
        currentSession: this.currentSessionId,
        systemStats: stats,
        recommendations: insights.recommendations
      };
    }
    
    return {
      enabled: false,
      systemStats: null,
      recommendations: ['ä½¿ç”¨enhancedSystemPromptProviderä»¥å¯ç”¨æ™ºèƒ½å¯¹è¯åŠŸèƒ½']
    };
  }

  /**
   * ğŸ›ï¸ æ™ºèƒ½ç³»ç»Ÿæ§åˆ¶
   */
  enableIntelligentChat(): void {
    this.isIntentSystemEnabled = true;
    if (this.promptProvider === enhancedSystemPromptProvider) {
      enhancedSystemPromptProvider.enableIntentSystem();
    }
    log.info('ğŸ§  [æ™ºèƒ½å¯¹è¯] å·²å¯ç”¨æ„å›¾è¯†åˆ«å’Œä¸Šä¸‹æ–‡åˆ†æ');
  }

  disableIntelligentChat(): void {
    this.isIntentSystemEnabled = false;
    if (this.promptProvider === enhancedSystemPromptProvider) {
      enhancedSystemPromptProvider.disableIntentSystem();
    }
    log.info('ğŸ”‡ [æ™ºèƒ½å¯¹è¯] å·²ç¦ç”¨ï¼Œå›åˆ°åŸºç¡€LLMæ¨¡å¼');
  }

  isIntelligentChatEnabled(): boolean {
    return this.isIntentSystemEnabled && this.promptProvider === enhancedSystemPromptProvider;
  }

  // ==================== ç§æœ‰è¾…åŠ©æ–¹æ³• ====================

  /**
   * åˆ†ææƒ…æ„ŸçŠ¶æ€
   */
  private analyzeEmotionalState(context: ConversationContext): string {
    if (context.isFrustration) return 'æŒ«è´¥';
    if (context.isCorrection) return 'çº æ­£ä¸­';
    
    switch (context.detectedIntent) {
      case 'debugging': return 'ç„¦è™‘';
      case 'casual_chat': return 'è½»æ¾';
      case 'tool_activation': return 'ç›®æ ‡å¯¼å‘';
      case 'complex': return 'å‹åŠ›è¾ƒå¤§';
      default: 
        return context.confidence > 0.7 ? 'ä¸“æ³¨' : 'æ¢ç´¢ä¸­';
    }
  }
}
