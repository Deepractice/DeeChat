import { BaseChatModel } from "@langchain/core/language_models/chat_models";
import { ChatOpenAI } from "@langchain/openai";
import { ChatAnthropic } from "@langchain/anthropic";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";

import { ModelConfigEntity } from '../entities/ModelConfigEntity';
import log from 'electron-log';

/**
 * LangChainæ¨¡å‹å·¥å‚
 * è´Ÿè´£æ ¹æ®é…ç½®åˆ›å»ºé€‚å½“çš„LangChainæ¨¡å‹å®ä¾‹
 */
export class LangChainModelFactory {
  /**
   * åˆ›å»ºèŠå¤©æ¨¡å‹
   * æ ¹æ®æä¾›å•†ç±»å‹é€‰æ‹©åˆé€‚çš„LangChainæ¨¡å‹å®ç°
   * å¯¹äºå·²çŸ¥çš„æä¾›å•†ä½¿ç”¨åŸç”ŸLangChainå®ç°ï¼Œå¯¹äºè‡ªå®šä¹‰æä¾›å•†ä½¿ç”¨ProjectSChatModel
   */
  static createChatModel(config: ModelConfigEntity): BaseChatModel {
    const provider = config.provider.toLowerCase();
    log.info(`ğŸ”§ [ModelFactory] å¼€å§‹åˆ›å»ºæ¨¡å‹ - Provider: ${provider}, Model: ${config.model}, BaseURL: ${config.baseURL}`)
    
    switch (provider) {
      case 'openai':
        log.info(`ğŸ¤– [ModelFactory] åˆ›å»ºChatOpenAIå®ä¾‹ - Model: ${config.model}`)
        return new ChatOpenAI({
          modelName: config.model,
          openAIApiKey: config.apiKey,
          configuration: {
            baseURL: config.baseURL
          },
          temperature: 0.7,
          maxTokens: 2000
        });
      
      case 'claude':
      case 'anthropic':
        log.info(`ğŸ§  [ModelFactory] åˆ›å»ºChatAnthropicå®ä¾‹ - Model: ${config.model}`)
        return new ChatAnthropic({
          modelName: config.model,
          anthropicApiKey: config.apiKey,
          temperature: 0.7,
          maxTokens: 2000,
          clientOptions: {
            baseURL: config.baseURL
          }
        });
      
      case 'gemini':
      case 'google':
        log.info(`ğŸŒŸ [ModelFactory] åˆ›å»ºChatGoogleGenerativeAIå®ä¾‹ - Model: ${config.model}`)
        // æ£€æŸ¥æ˜¯å¦æœ‰ä»£ç†è®¾ç½®
        const proxyUrl = process.env.HTTPS_PROXY || process.env.HTTP_PROXY
        const clientOptions: any = {}

        if (proxyUrl) {
          console.log(`ä½¿ç”¨ä»£ç†è®¿é—®Gemini API: ${proxyUrl}`)
          // ä¸ºGoogle Generative AIè®¾ç½®ä»£ç†
          clientOptions.httpAgent = require('https-proxy-agent')(proxyUrl)
        }

        if (config.baseURL && config.baseURL !== 'https://generativelanguage.googleapis.com') {
          clientOptions.baseURL = config.baseURL
        }

        return new ChatGoogleGenerativeAI({
          model: config.model,
          apiKey: config.apiKey,
          temperature: 0.7,
          maxOutputTokens: 2000,
          ...(Object.keys(clientOptions).length > 0 ? { clientOptions } : {})
        });
      
      // å¯¹äºè‡ªå®šä¹‰æä¾›å•†ï¼Œä½¿ç”¨ChatOpenAI with è‡ªå®šä¹‰baseURL
      // å¤§å¤šæ•°è‡ªå®šä¹‰APIéƒ½æ˜¯OpenAIå…¼å®¹çš„
      default:
        log.info(`ğŸ”§ [ModelFactory] åˆ›å»ºé»˜è®¤ChatOpenAIå®ä¾‹ - Provider: ${provider}, Model: ${config.model}`)
        return new ChatOpenAI({
          apiKey: config.apiKey,
          model: config.model,
          configuration: {
            baseURL: config.baseURL
          },
          temperature: 0.7,
          maxTokens: 2000
        });
    }
  }

  /**
   * è·å–æ¨¡å‹çš„é»˜è®¤å‚æ•°
   */
  static getDefaultModelParams(provider: string): any {
    switch (provider.toLowerCase()) {
      case 'openai':
        return {
          temperature: 0.7,
          maxTokens: 2000
        };
      
      case 'claude':
      case 'anthropic':
        return {
          temperature: 0.7,
          maxTokens: 2000
        };
      
      case 'gemini':
      case 'google':
        return {
          temperature: 0.7,
          maxOutputTokens: 2000
        };
      
      default:
        return {
          temperature: 0.7,
          maxTokens: 2000
        };
    }
  }

  /**
   * åˆ›å»ºå¸¦æœ‰è‡ªå®šä¹‰å‚æ•°çš„èŠå¤©æ¨¡å‹
   */
  static createChatModelWithParams(
    config: ModelConfigEntity, 
    params: Record<string, any>
  ): BaseChatModel {
    const provider = config.provider.toLowerCase();
    
    switch (provider) {
      case 'openai':
        return new ChatOpenAI({
          modelName: config.model,
          openAIApiKey: config.apiKey,
          configuration: {
            baseURL: config.baseURL
          },
          ...params
        });
      
      case 'claude':
      case 'anthropic':
        return new ChatAnthropic({
          modelName: config.model,
          anthropicApiKey: config.apiKey,
          clientOptions: {
            baseURL: config.baseURL
          },
          ...params
        });
      
      case 'gemini':
      case 'google':
        return new ChatGoogleGenerativeAI({
          model: config.model,
          apiKey: config.apiKey,
          ...params
        });
      
      default:
        // å¯¹äºè‡ªå®šä¹‰æä¾›å•†ï¼Œä½¿ç”¨ChatOpenAI with è‡ªå®šä¹‰baseURL
        return new ChatOpenAI({
          apiKey: config.apiKey,
          model: config.model,
          configuration: {
            baseURL: config.baseURL
          },
          ...params
        });
    }
  }
}
