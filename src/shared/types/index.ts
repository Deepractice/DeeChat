// MCPå·¥å…·æ‰§è¡Œè®°å½•ç±»å‹
export interface ToolExecution {
  id: string
  toolName: string
  params: any
  result?: any
  error?: string
  duration?: number
  timestamp: number
}

// èŠå¤©æ¶ˆæ¯ç±»å‹
export interface ChatMessage {
  id: string
  role: 'user' | 'assistant' | 'system'
  content: string
  timestamp: number  // ä½¿ç”¨Unixæ—¶é—´æˆ³ä¿æŒä¸€è‡´æ€§
  modelId?: string
  toolExecutions?: ToolExecution[]  // æ–°å¢ï¼šå·¥å…·æ‰§è¡Œè®°å½•
  metadata?: {
    tokens?: number
    responseTime?: number
    error?: string
  }
}

// APIå“åº”ç±»å‹
export interface ApiResponse<T = any> {
  success: boolean
  data?: T
  error?: string
  message?: string
}

// æ¨¡å‹æä¾›å•†ç±»å‹ - æ”¯æŒæ›´å¤šæä¾›å•†å’Œè‡ªå®šä¹‰
export type ModelProvider = 'openai' | 'claude' | 'grok' | 'mistral' | 'ollama' | 'custom' | string

// æ¨¡å‹çŠ¶æ€ç±»å‹
export type ModelStatus = 'available' | 'error' | 'untested' | 'testing'

// å…ˆå¯¼å…¥å®ä½“ç±»å‹
import { ModelConfigEntity } from '../entities/ModelConfigEntity'
import type { ModelConfigData, TestResult, ValidationResult } from '../entities/ModelConfigEntity'
import { ChatSessionEntity } from '../entities/ChatSessionEntity'
import type { ChatSessionData } from '../entities/ChatSessionEntity'
import { UserPreferenceEntity } from '../entities/UserPreferenceEntity'
import type { UserPreferenceData } from '../entities/UserPreferenceEntity'
import type { LLMRequest, LLMResponse, ModelConfigTemplate } from '../interfaces/IModelProvider'

// é‡æ–°å¯¼å‡ºå®ä½“ç±»å‹
export { ModelConfigEntity, ChatSessionEntity, UserPreferenceEntity }
export type { ModelConfigData, TestResult, ValidationResult, ChatSessionData, UserPreferenceData, LLMRequest, LLMResponse, ModelConfigTemplate }

// æ¨¡å‹é€‰æ‹©ç­–ç•¥ç±»å‹
export type ModelSelectionStrategy = 'remember_last' | 'priority' | 'manual'

// å‰ç«¯çŠ¶æ€ç±»å‹ï¼ˆåœ¨å¯¼å…¥å®ä½“ç±»å‹ä¹‹åå®šä¹‰ï¼‰
export interface ModelManagementState {
  configs: ModelConfigEntity[]
  currentSessionModel: string | null
  userPreferences: UserPreferenceEntity | null
  isLoading: boolean
  error: string | null
  testResults: Map<string, TestResult>
}

export interface ChatState {
  sessions: ChatSessionEntity[]
  currentSessionId: string | null
  messages: ChatMessage[]
  isLoading: boolean
  error: string | null
}

// ç»„ä»¶Propsç±»å‹
export interface ModelConfigCardProps {
  config: ModelConfigEntity
  onTest: (id: string) => void
  onSave: (config: ModelConfigEntity) => void
  onDelete: (id: string) => void
  onToggleEnabled: (id: string) => void
  testResult?: TestResult
  isLoading?: boolean
}

export interface ModelSelectorProps {
  sessionId: string
  selectedModelId?: string
  onModelChange: (modelId: string) => void
  availableModels: ModelConfigEntity[]
  disabled?: boolean
}

export interface ChatInputProps {
  onSendMessage: (message: string) => void
  disabled?: boolean
  placeholder?: string
  maxLength?: number
}

// è¡¨å•ç±»å‹
export interface ModelConfigFormData {
  name: string
  provider: ModelProvider
  model: string
  apiKey: string
  baseURL: string
  priority: number
  isEnabled: boolean
}

export interface UserPreferenceFormData {
  defaultModelId?: string
  modelSelectionStrategy: ModelSelectionStrategy
  autoSwitchOnFailure: boolean
}

// é”™è¯¯ç±»å‹
export class ModelConfigError extends Error {
  constructor(message: string, public code?: string) {
    super(message)
    this.name = 'ModelConfigError'
  }
}

export class ModelProviderError extends Error {
  constructor(message: string, public provider?: string) {
    super(message)
    this.name = 'ModelProviderError'
  }
}

export class ModelSelectionError extends Error {
  constructor(message: string, public sessionId?: string) {
    super(message)
    this.name = 'ModelSelectionError'
  }
}

// å·¥å…·å‡½æ•°ç±»å‹
export type DeepPartial<T> = {
  [P in keyof T]?: T[P] extends object ? DeepPartial<T[P]> : T[P]
}

export type RequiredFields<T, K extends keyof T> = T & Required<Pick<T, K>>

export type OptionalFields<T, K extends keyof T> = Omit<T, K> & Partial<Pick<T, K>>

// å…¼å®¹æ—§ç‰ˆæœ¬çš„ç±»å‹ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
export interface LLMConfig {
  provider: 'openai' | 'claude' | 'local'
  apiKey: string
  baseURL?: string
  model: string
  temperature?: number
  maxTokens?: number
}

export interface AppConfig {
  llm: LLMConfig
  ui: {
    theme: 'light' | 'dark' | 'auto'
    language: 'zh' | 'en'
  }
  chat: {
    maxHistoryLength: number
    autoSave: boolean
  }
}

export interface ChatSession {
  id: string
  title: string
  messages: ChatMessage[]
  createdAt: number
  updatedAt: number
  selectedModelId?: string
}

// ğŸ”¥ æ–°å¢ï¼šå¢å¼ºçš„ä¼šè¯ç±»å‹ï¼ŒåŒ…å«å®Œæ•´çš„æ¨¡å‹é…ç½®
export interface EnhancedChatSession extends ChatSession {
  selectedModelConfig?: ModelConfigEntity  // å®Œæ•´çš„æ¨¡å‹é…ç½®å¯¹è±¡
  modelDisplayName?: string               // æ¨¡å‹æ˜¾ç¤ºåç§°
}

export interface AppState {
  config: AppConfig
  currentSession: ChatSession | null
  sessions: ChatSession[]
  isLoading: boolean
  error: string | null
}

// åˆ«åä¿æŒå…¼å®¹æ€§
export type APIResponse<T = any> = ApiResponse<T>
